1 Course Objective Understanding of the issues involved in distributed computer systems and to investigate the fundamental characteristics of distributed computing systems, including their models, architectures and designs that exploit rapidly evolving technology. 2 Course Introduction Prerequisites: - Operating System - Computer Networks 3 Course Outline • Unit1: - Introduction: Introduction to Distributed Systems, Design Goals, Types ofDistributed systems - Architecture: system architectures and fundamental models, middleware, Threads, virtualization, client-Server Model, Code migration •Unit2: Inter-process communication: RemoteProcedure Call, message oriented Communication fundamentals, communication, and stream orientedcommunication, multicast communication •Unit3: - Time Synchronization: clock synchronization, logical clocks, - Resource Allocation Synchronization: mutual exclusion algorithms: centralized, decentralized, distributed and token ring algorithms, election algorithms. 4 Course Outline Unit 4: Replication and Consistency need for replication, consistency models: data centric and client centric consistency models, replica management, consistency protocols: continuous, primary-based, replicated-write and cache-coherence protocols. Unit 5: Fault Tolerance basic concepts and failure models, process resilience, reliable clientserver and group communication, distributed commit recovery mechanisms Unit 6: -Security in Distributed Systems - Security in distributed systems, secure channels, authentication, integrity and confidentiality, access control, security management. - Naming: Flat naming approaches, structured naming, name space and resolution, attribute- based naming, directory services, LDAP, decentralized implementations. - File Systems –Distributed file services, example file systems Text Text Books: Distributed Systems: Principles and Paradigms, 2nd Ed., Andrew S. Taenbaum and Maarten Van Steen, Prentice Hall, 2007. References: • Distributed Operating Systems: Concepts and Design, P.K.Sihna, PHI, 2007. •Distributed Operating Systems and Algorithms. R. Chow, T. Johnson. AddisonWesley Publishing Company, 1997. ISBN 0-201-49838-3. •Distributed Systems: Concepts and Design, 4th Ed by Coulouris, G, Dollimore, J., and Kindberg, T., Addison-Wesley, 2006. 5 6 Definition of a Distributed System (1) •A distributed system is: A collection of independent computers that appears to its users as a single coherent system. • Utilizes the power of : - Advancement in computing power of microprocessor - High speed network communication between computers 7 Some uses.. •Pool of processors dynamically assigned to users to execute a job in the best manner possible •Large bank with branch offices over world, each office with: - Master computer to store local accounts and handle local transactions - Ability to communicate with other branch offices and central computer -Transactions can be made without regard to where customer account is located. Definition of a Distributed System (2) •Middleware to support heterogeneous computers and networks and offering a single system overview. •Middleware layer extends over multiple machines. •Applications distributed over computers. 8 9 Goals •Resource Availability •Distribution Transparency •Openness •Scalability 10 Resource Availability •Access to Remote resources by all users eg: printers, computers, storage •Helps collaborate and exchange information - exchanging files, mail. documents, audio, and video - electronic commerce •Threat to Security Transparency in a Distributed System Different forms of transparency in a distributed system. 11 12 Openness •Offers services according to standard rules in the form of interfaces described by Interface Definition Languages (IDL) •Allows an arbitrary process to talk to another process • Extensible: add new components or replace old ones 13 Scalability •Add more users and resources •Geographical scalability wrt to distribution of users resources across different places •Administrative scalability 14 Scalability Problems when users increase Examples of scalability limitations. Concept Example Centralized services A single server for all users Centralized data A single on-line telephone book Centralized algorithms Doing routing based on complete information 15 Centralized algorithm •Collect information about load on machines and lines and compute optimal routes for communication. •Collecting and Transporting information to centralized server and then distributing information after analysis overloads network. •Distributed algorithms characteristics: -No machine with complete information about system state -Machine decision based on local information only -Algorithm not ruined by failure of a single machine -Global clock 16 Geographic scalability •Client server architecture which requires synchronous communication works well on a LAN. - client, blocks until a reply is sent back •Communication delays in WAN for response can be longer •Unreliability of communication over WAN - local-area networks generally provide highly reliable communication facilities based on broadcasting 17 Administrative scalability •Scaling across multiple independent administrative domainsresolving conflicting policies for resource usage, management,security •Security issues across domains 18 Scaling Techniques 1. Hiding Communication latencies 1. Distribution 1. Replication Hiding Communication latencies 1.4 The difference between letting: a) a server or b) a client check forms as they are being filled 19 20 Hiding Communication latencies (2) •Server may check for syntactic errors before accepting an entry •Better solution: code for filling in form, and possibly checking entries, to the client, and have the client return a completed form Eg: Web in the form of Java applets and Javascript 21 Scaling Techniques –Distribution (1) •Splitting components into smaller parts and spreading them across system •Eg: Domain Name System name space is hierarchically organized as tree of domains, which are divided into nonoverlapping zones, Scaling Techniques –Distribution (2) 1.5 An example of dividing the DNS name space into zones and distributing the naming service Resolving “nl. vu.cs.flits”: Traverse Z3,Z2,Z1 22 23 Scaling Techniques - Replication •Replicate components across distributed system – increasing availability and balancing load between components for better performance eg: Geographically close copy can hide communication latency •Caching is a form of replication – copy of resource in the proximity of the client accessing the resource - Difference from replication: on-demand rather than planned •Leads to consistency problems - update must be immediately be propagated to all other copies - Two concurrent updates must be made in the same order. •Requires global synchronization 24 Scalability Conclusion • Size scalability is the least problematic • Geographical scalability is a much tougher problem • Administrative scalability seems to be the most difficult one, because need to solve nontechnical problems - peer-to-peer technology demonstrates what can be achieved if end users simply take over control 25 Advantages over Centralized systems •Resource utilization provides better performance for the price. •Provide more computing power compared to centralized mainframe •Computer supported cooperative work involving spatially separated machines •Higher reliability •Incremental growth in computing power Advantages over PC 26 Disadvantages of DS 27 28 Classification •SISD: Single Instruction and Single stream (traditional computer) •SIMD: Single Instruction and Multiple Stream (Array of processors with one instruction to be processed on multiple data handled by multiple data units in parallel) eg: supercomputers •MIMD: Multiple instruction and multiple streams – group of independent computers each with its program counter, program and data. (Distributed Systems) MIMD Classification Single medium connecting all machines Wires from machine to machine Less delay high data rate - Parallel 29 High delay low data rate - Distributed Hardware Concepts Different basic organizations and memories in distributed computersystems 30 Multiprocessors (1) A bus-based multiprocessor. •Bus has address lines, data lines and control lines in parallel. •Single coherent memory ( memory written is readable to others coherently after a minute delay) •Cache memory to increase performance •Write through cache for uniformity of caches (i.e word written to cache is written to memory as well so that new CPU accessing it gets updated value) •Limited can have at most 64 CPUs 31 32 Multiprocessors (3) •Write through cache for uniformity of caches (i.e word written to cache is written to memory as well so that new CPU accessing it gets updated value) •Snoopy cache – cache constantly monitors the bus for any write occurring to a memory address that is in the cache and updates it. Multiprocessors (2) a)A crossbar switch b)An omega switching network 1.8 33 Multiprocessor quir ire •Crossbar Switch: - Every intersection between CPU and memory is a physical switch that can be opened or closed -Many CPUs can access memory at the same time provided memory locations are different -Disadvantage – n CPU, n memory re e switches •Omega network: -Contains 2x2 switch -n CPU n memory location requ -Delay due to switching stages -Conclusion: tightly coupled, shared memory multiprocessor is difficult and expensive 34 Bus Based Multicomputer •Each computer has own memory and communicate across bus •Since traffic is less compared to multiprocessor bus can be a lower speed LAN 35 Homogeneous Multicomputer Systems a) Grid b) Hypercube 1-9 36 37 Types of Distributed Systems • Distributed Computing System -used for high-performance computing tasks •Distributed Information System – - interoperatabilty & communication of network applications in organization •Distributed Pervasive Systems 38 Divyashikha Sethia (DTU) Distributed Computing System(1) i) Cluster computing - underlying hardware consists of similar workstations closely connected by means of a highspeed LAN - each node runs same OS ii) Grid computing -consists of distributed systems often constructed as federation of computer systems, where each system may fall under different Administrative domain, and may have different hardware, software, and deployed network technology. Cluster Computing •Build supercomputer by simply hooking up collection of simple computers in high-speed network. •Cluster computing is used for parallel programming in which single (compute intensive) program is run in parallel on multiple machines 39 40 Linux Cluster •Each cluster consists of collection of compute nodes controlled and accessed by master node that: - allocates nodes to particular parallel program - maintains a batch queue of submitted jobs - provides interface for users of system. •Master runs middleware for execution of programs and management of cluster, while compute nodes only need a standard OS. •Middleware has libraries for executing parallel programs and effectively provides advanced message-based communication facilities, handling faulty processes, security, etc. 41 Grid Computing •Computing systems have a high degree of heterogeneity •Resources from different organizations are brought together to allow the collaboration •Software provides access to resources from different administrative domains, users and applications that belong to a specific virtual organization Layered architecture for grid computing •Fabric layer - Provides interfaces to local resources at a specific site. - Allows sharing of resources within a virtual organization •Connectivity Layer - Communication protocol for grid transactions for usage of multiple resources - Security protocols to authenticate users and resources 42 Middleware Layer • Resource Layer - Responsible for managing a single resource -Functions for obtaining configuration information on a specific resource, perform specific operations such as creating a process or reading data • Collective layer - Access multiple resources -Services for resource discovery, allocation & scheduling tasks onto multiple resources, data replication • Application layer - Applications that operate within virtual organization &which use grid computing 48 Layered architecture for grid computing 44 Divyashikha Sethia (DTU) Difference between Cluster and Grid computing Characteristics of Grid Computing •Loosely coupled (Decentralization) Diversity and Dynamism Distributed Job Management & scheduling Characteristics of Cluster computing •Tightly coupled systems Single system image Centralized Job management & scheduling system 45 Divyashikha Sethia (DTU) Distributed vs Cloud Computing •Distributed computing/distributed system involve breaking up a problem which can be solved by a group of computers working at the same time. •Cloud computing usually refers to providing a service via the internet. That service can be pretty much anything, from business software that is accessed via the web to off-site storage or computing resources. Cloud vs Grid Computing 51 •Grid computing: -Used in environments where users make few but large allocation requests. Eg: lab may have 1000 node cluster and users make allocations for all 1000, or 500, or 200, etc. - only a few of these allocations can be serviced at a time and others need to be scheduled for when resources are released -results in sophisticated batch job scheduling algorithms of parallel computations. •Cloud computing: -lots of small allocation requests. The Amazon EC2 accounts are limited to 20 servers each by default and lots and lots of users allocate up to 20 servers out of the pool of many thousands ofservers at Amazon. -Allocations are real-time and there is no provision for queuing Distributed Information System Networked applications can be integrated to form enterprise-wide information system •Types: i) Transaction Processing Systems (Database – self study) -server running application (often including a database) and makingit available to remote programs, called clients. - clients wrap a number of requests, possibly for differentservers, into a single larger request and have it executed as a distributed transaction ii) Enterprise Application Integration - integration should also take place by letting applicationscommunicate directly with each other 52 Enterprise Application Integration Integrate applications independent from their databases &communicate directly through Middleware in the form of : i) Remote procedure calls (RPC): - Application component can effectively send request to another application component by doing local procedure call, which resultsin request sent as message to callee. -Result sent back and returned to application as result of procedu5 r 3 e call Enterprise Application Integration ii) Remote Method Invocation ( RMI) - allow calls to remote objects instead of application •Disadvantage: caller and callee need to be up and running at time of communication 49 50 Message Oriented middleware (MOM) •Disadvantage of RPC & RPI: - caller and callee need to be up and running at time of communication - need to know exactly how to refer to each other •Message Oriented Middleware (MOM) -applications send messages to logical contact points, described by means of subject and specifying type of message. -Middleware takes care those messages are delivered to applications. - Publish/subscribe systems form an important and expanding class of distributed systems 51 Distributed Pervasive System ⮚Small, battery-powered, mobile, devices with only a wireless connection hence not very stable ⮚ Configured by owners, but should automatically discover environment ⮚Requirements: 1. Embrace contextual changes. • Device aware of environmental changes • Network disconnectivity :automatically connect to another network/ appropriate actions 2. Encourage ad hoccomposition. • Easy to configuration of applications 3. Recognize sharing as thedefault. • Easily read, store, manage, and share information • Efficient discovery of services 52 Example of pervasive systems ⮚Home Systems: • PCs, gaming devices, smart phones, surveillance cameras, clocks, kitchen appliances hooked to distributed system • Self configuring and self managing • Universal Plug and Play (UPnP) standards by which devices automatically obtain IP addresses, can discover each other ⮚Electronic Health Care System • Devices to monitor well-being of individuals and to automatically contact physicians when needed and avoid hospitalization • Various sensors organized in a (preferably wireless) body-area network (BAN) minimally hindering a person, operating while person is on the move Pervasive Electronic Health Care Monitoring a person in a pervasive electronic health care system: (a)Local hub collects data as needed and offloads it to external storage device time to time. (b) Continuous wireless connection hooked up to externalstorage 53 54 Sensor Networks ⮚Used for processing information and form the basis for many mediumscale distributed systems ⮚Consists of tens to hundreds or thousands of relatively small nodes, each equipped with a sensing device, battery operated ⮚Distributed Database Sensor Network database Storing and processing data: (a) only at the operator's site or (b) only at the sensors. 60 a) Sensors do not cooperate but simply send their data to centralized database located at operator's site • may waste network resources and energy b) Forward queries to relevant sensors and let each compute an answer, requiring operator to sensibly aggregate returned answers • wasteful as it discards aggregation capabilities of sensors which would allow much less data to be returned to operator Sensor Network database 57 In-network processing ⮚ Forward query to all sensor nodes along a tree encompassing all nodes and subsequently aggregate results as they are propagated back to root, where initiator is located ⮚ Aggregation will take place where two or more branches of the tree come to together ⮚ TinyDB, implements a declarative(database) interface to wireless sensor networks • Use any tree-based routing algorithm. • Intermediate node collect and aggregate tree results from its children, along with its own findings, and send that toward root 58 Summary ⮚Distributed systems consist of autonomous computers that work together to give the appearance of a single coherentsystem. ⮚Advantage: • Makes easier to integrate different applications running on different computers into a single system. ⮚Issues : Resource Availability, Distribution Transparency, Openness, Scalability ⮚Types of Systems: • Distributed Computing System, Distributed Information System, Distributed Pervasive Systems Resources Divyashikha Sethia (DTU) 64 •Distributed Systems - Tanenbaum •http://www.jatit.org/research/introduction_grid_computing.htm •http://www.thepicky.com/tech/difference-cloud-computing-vs-gridcomputing/ Copy protected with Online-PDF-No-Copy.com Communication in Distributed Systems ⚫ Communication in Distributed Systems based on low level message passing offered by underlying network ⚫ Three popular models of communication: ⚫ Remote Procedure Calls (RPC) ⚫ Message-oriented Middleware (MOM) ⚫ Data Streaming, discussion of SCTP, 3GPP ⚫ Sending data to multiple receivers or Multicasting ⚫ Interprocess Communication is part of the Client/Server Computing Model ⚫ A client is an application or a process that requests a service from some other application or process. ⚫ A server is an application or a process that responds to a client request. ⚫ Both client/server applications perform specialized functions in a distributed computing environment. ⚫ Intraprocess communication used between homogeneous systems. Example : using named pipes, named queues, shared memory etc ⚫ Focus of this presentation is Interprocess Communication ⚫ In between the end users and large pool of computing resources, many applications act as both a client and a server, depending on the situation. ⚫ Interprocess communication is necessary to communicate between heterogeneous systems ⚫ Protocols govern the format, contents and meaning of messages Two main types of Protocols: ▪ Connection-oriented: Sender and receiver establish a connection and negotiate the protocol to use before exchanging data. At the end of commiunication, terminate or release the connection. An example: TCP ▪ Connectionless: No connection is set up in advance. Sender transmits message when ready. An example: UDP Main differences between connection-oriented and connectionless protocols: 1. Connection-oriented is reliable, while the other is not. 2. Connection-oriented is fully duplex 3. Connection-oriented is byte-stream service with no structure 4. Error checking an essential component of unreliable connectionless protocol 5. Connectionless protocol transfers packets of data and uses a protocol port address to specify receiver process

⚫ Lower-Level Protocols ⚫ Implemented in physical layer and data link layer of the stack. Groups data bits into frames and adds a pattern called checksum at either end of frame ⚫ Network layer chooses best path from sender to receiver by routing ⚫ Transport Protocols • TCP • UDP ⚫ Higher Level Protocols • FTP • HTTP Middleware Protocols: ⚫ Examples are Authentication and Authorization protocols, commit protocols in transaction databases ⚫ Middleware protocols support high level communication services • Protocols that allow a process to call a procedure or invoke an object on a remote machine transparently. An example RPC/RMI • Protocols that support the setting up and synchronizing of streams for transferring real-time data such as multimedia applications. An example: SCTP • Protocols that support reliable multicast services to a WAN Application Middleware Transport Network Data Link Physical Network Application Protocol Middleware Protocol Transport Protocol Network Protocol Data Link Protocol Physical Protocol 6 5 4 3 2 1 Protocol Stack Types of Communication • Persistent communication: Message submitted for transmission stored by communication middleware as long as it takes to deliver it to the receiver. Neither sending application nor receiving application need to be executing. • Transient communication: Message stored by communication system only as long as sending and receiving application are executing. • Asynchronous communication: Sender continues immediately after submitting message for transmission. Message temporarily stored by middleware on submission. • Synchronous communication: Sender blocks until message received and processed and receiver returns acknowledgement. Remote Procedure Calls ⚫ Remote procedure calls can simplify the way IPCs are conducted through the network. ⚫ Client applications use the client side network API to call RPCs. ⚫ Server side of the network API turns the RPCs into local function calls. ⚫ Return value being transmitted back to the client application again through the network. ⚫ The OSI layers are transparent to the client application, as if it is making a local function call. ⚫ The RPC provided by Windows enable applications that use RPC to communicate with applications running with other operating systems that support DCE (Distributed Computing Environment). RPC automatically supports data conversion to account for different hardware architectures and for byte-ordering between dissimilar environments. Synchronous RPC Operation: ⚫ Process on machine A calls procedure on machine B, the calling process on A is suspended and execution of the called procedure takes place on B. ⚫ Information is transported from caller to callee in the parameters and comes back in the procedure result ⚫ No message passing visible to programmer ⚫ Client and Server stubs are used ⚫ Client stub takes its parameters and packs them into a message (parameter marshalling) and sends them to the server stub Parameter Passing: ⚫ Passing Value Parameters • Client stub takes parameters and puts them in the message. It also puts the name or number of the procedure to be called in the message • When message arrives at server, server stub examines the message to see which procedure is needed and then makes appropriate call. Stub takes the result and packs it into a message. Message is sent back to client stub. • Client stub unpacks the message to extract the result and returns it to waiting client procedure ⚫ Passing Reference Parameters • Pointers and references passed by copying the data structure such as array into message and sent to server • Server stub calls server with a pointer to this array • Server makes changes using this pointer that also affects the message buffer inside server stub • Server finishes its work, original message sent back to client stub which copies it back to the client. Asynchronous RPC: ⚫ Client continues immediately after issuing RPC request and receiving acknowledgement from server, it is not blocked. ⚫ Server sends immediately a reply or acknowledgement to the client the moment RPC request is received ⚫ Server then calls requested procedure ⚫ One-way RPC: Client does not wait for even an acknowledgement from server. Reliability not guaranteed as client has no acknowledgement from server. ⚫ Deferred synchronous RPC is a combination of two asynchronous RPCs, where client polls the server periodically to see whether results are available yet rather than server calling back the client. Message-Oriented Communication ⚫ RPC assumes that receiver process is executing at the time a request is issued ⚫ Message-oriented communication such as message-queuing systems is therefore needed to allow processes to exchange information even if one party is not executing at the time the communication is initiated. ⚫ Message-oriented-model (MOM) offered by transport layer, as part of middleware solution Berkeley Sockets ⚫ Sockets interface introduced in 1970s in Berkeley Unix ⚫ Standardizes the interface of the transport layer to allow programmers the use of messaging protocols through simple set of primitives ⚫ Another interface XTI stands for X/Open Transport Interface, also formerly called Transport Layer Interface (TLI) developed by AT&T ⚫ Sockets and XTI similar in their model of network programming but differ in their set of primitives ⚫ Socket forms an abstraction over the communication end point to which an application can write data that are sent over the underlying network and from which incoming data can be read. ⚫ Servers execute the first four primitives in table ⚫ When calling the socket primitive, the caller creates a new communication end point for a specific transport protocol. Internally, the OS reserves resources to accommodate sending and iifthifitl • Bind primitive associates a local address with a newly-created socket. For example, server should bind the IP address of its machine together with a known port # to a socket • Binding tells the OS that the server wants to receive messages only on the specified address and port • Listen primitive is called only in the case of connection-oriented communication. It is a nonblocking call that allows the local OS to reserve enough buffers for a specified # of connections that the caller is willing to accept • A call to accept primitive blocks the caller until a connection request arrives. When the request arrives, the local OS creates a new socket with same properties as the original one and returns it to caller. Server can wait for another connection request on the original socket • Connect primitive on client requires that the caller specifies the transport level address to which a connection request is to be sent • Client is blocked until a connection is set up, after which info can be exchanged using send/receive • Closing the connection is symmetric as both server and client call the close primitive Primitive Meaning Socket Create a new communication end point Bind Attach a local address to a socket Listen Announce willingness to accept connections Accept Block caller until connection request arrives Connect Actively attempt to establish a connection Send Send some data over the connection Receive Receive some data over the connection Close Release the connection Message-Passing Interface ⚫ A standard defined for message passing ⚫ Hardware and platform independent ⚫ Designed for parallel applications and transient communication. ⚫ Makes use of underlying network • Assumes that serious failures such as process crashes or network partitions are fatal and do not require automatic recovery • MPI assumes communication takes place within a known group of processes • Each group is assigned an identifier • Each process within a group is also assigned a local identifier • A (groupID, processID) pair uniquely identifies the source or destination of a message, and is used instead of a transport-level address • Several possibly overlapping groups of processes involved in a computation, executing at the same time • MPI has messaging primitives to support transient communication shown in next table Primitive Meaning MPI_bsend Append outgoing message to a local send buffer MPI_send Send a message and wait until copied to local or remote buffer MPI_ssend Send a message and wait until receipt starts MPI_sendrecv Send a message and wait for reply MPI_isend Pass reference to outgoing message, and continue MPI_issend Pass reference to outgoing message, and wait until receipt starts MPI_recv Receive a message; block if there is none MPI_irecv Check if there is an incoming message, butdonotblock • Transient asynchronous communication is supported by MPI_bsend primitive • Sender submits a message for transmission which is copied to a local buffer in MPI runtime system. Sender continues after message is copied. Local MPI runtime system will remove the message from its local buffer and transmit as soon as a receiver has called a receive primitive • MPI_send is a blocking send operation with implementation dependent semantics • It may either block the caller until the specified message has been copied to the MPI runtime system at the sender’s side, or until the receiver has initiated a receive operation • MPI_ssend implements synchronous communication by which the sender blocks until its request is accepted for further processing • MPI_sendrecv when called by sender, sends a request to the receiver and blocks until the latter returns a reply. This

• MPI_isend allows the sender to pass a pointer to the message and the MPI runtime system takes care of the communication. Sender continues. • MPI_issend allows the sender to pass a pointer to MPI runtime system. When runtime system indicates it has processed the message, sender knows that receiver has accepted the message. • Caller is blocked until message arrives when MPI_recv is called to receive a message • Asynchronous variant MPI_irecv called by receiver indicates it is prepared to accept message Message-Oriented Persistent Communication ⚫ Message Oriented Middleware(MOM) or message queuing systems provide support for persistent asynchronous communication ⚫ Intermediate-term storage capacity for messages. Does not require sender/receiver to be active during message transmission ⚫ Slower than Berkeley sockets and MPI Message-Queuing Model ⚫ Applications communicate by inserting messages in specific queues ⚫ Messages are forwarded over a series of communication servers and delivered to the destination, even if it was down when message was sent ⚫ Each application has its own private queue to which other applications can send messages ⚫ Sender is informed that the message will be eventually inserted in the receiver’s queue. No time is specified. ⚫ Neither sender nor receiver need to be executing when message is placed in the queue ⚫ Loosely coupled communication with sender and receiver executing independent of each other. Primitive Meaning Put Append a message to a specified queue. A nonblocking call by sender. Get Block until specified queue is non-empty and remove the first message Poll Check a specified queue for messages and remove the first. Never block. Notify Install a handler as a callback function to be called when a message is put into a specified queue Architecture of Message Queuing System ⚫ Source queue to put message is local to sender ⚫ Message can be read only from local queue ⚫ Message put into a queue will contain the specification of a destination queue to which it should be transferred ⚫ Message queuing system responsible to provide the queues to sender/receiver and transfer messages from source to destination queue. ⚫ Message queuing system maintains mapping of queues distributed across multiple machines to network locations – a distributed database of queue names to network locations, similar to DNS. ⚫ Queues managed by Queue Managers, who interact with the application that is sending or receiving a message. Special queue managers operate as routers/relays that forward incoming messages to other queue managers ⚫ Message-queuing system may grow into a complete application level overlay network on top of existing computer network ⚫ Relays/routers help build scalable messaging systems ⚫ Relays allow secondary processing of messages, for example, a message may need to be logged for reasons of fault tolerance or security ⚫ Relays can be used for multicasting purposes. Incoming message put into each send queue. E-mail Systems • E-mail systems use underlying transport services. Example, mail protocol for the Internet-SMTP, a message is transferred by setting up a direct TCP connection to the destination mail server. Generally no routing is used. • Provide direct support for end users when compared to message-queuing system • E-mail systems have specific requirements such as automatic message filtering, support for advanced messaging databases to retrieve old messages etc • Message queuing system enables persistent communication between processes. Wide range of applications including e-mail. Stream-oriented Communication ⚫ Communication discussed till now dealt with independent, complete units of information and time had no effect on correctness of the communication ⚫ Stream communication such as audio or video stream in contrast to above are time-dependent ⚫ Information is represented in different formats such as GIF/JPEG for images, audio streams are encoded by taking 16-bit samples using PCM ⚫ In continuous representation media, temporal relationship between data is retained in order to correctly interpret the data. For example, motion can be represented by a series of images with successive images displayed at uniform spacing T in time (about 30-40 msec per image) ⚫ In discrete representation media, temporal relationships between data is not fundamental to correctly interpreting the data. Examples are text, still images etc ⚫ Data stream is a sequence of data units that can be applied to discrete as well as continuous media. Examples are UNIX pipes, TCP/IP connections of byte-oriented discrete data streams. Playing an audio file requires setting up a continuous data stream between the file and the audio device ⚫ Time is crucial to continuous data streams ⚫ Three types of transmission modes exist for data streams ⚫ Asynchronous transmission mode where data items are transmitted one after the other but no time constraints as to when the transmission of each item takes place. Example for discrete data streams : file transmission ⚫ Synchronous transmission mode where there is a maximum end-to-end delay defined for each data unit in stream. Example is Temperature sampled by sensors and passed over network ⚫ Isochronous transmission mode where time constraint is rigid and data units are transferred subject to maximum and minimum end-end delay (bounded (delay) jitter). Example are distributed multimedia systems such as audio/video ⚫ Focus in the presentation is on continuous data streams (streams) using isochronous transmission ⚫ Simple stream consists of single sequence of data ⚫ Complex stream consists of several related simple streams called substreams that are interdependent on each other based on time. Example is a video stream such as movie where two substreams continuously synchronized to transmit audio for the movie, a video substream, and a substream containing subtitles for the deaf or different language translation. All substreams are synchronized.

⚫ Architecture in the figure reveals some issues such as compression needed to reduce required storage and network capacity especially more for video than audio ⚫ Quality of transmission and synchronization to be controlled ⚫ Timing requirements expressed by Quality of Service(QoS) QoS for continuous data streams concerns the timeliness, volume and reliability of transmission. QoS Specification ⚫ The required bit rate at which data is transported ⚫ Maximum delay until a session is set up(i.e., when an application can start sending the data). ⚫ Maximum end-to-end delay ⚫ Maximum delay variance or jitter Enforcing QoS • Use buffers to reduce jitter • Use forward error correction to compensate for lost packets- encode the outgoing packets such that any k out of n received packets is enough to reconstruct k correct packets • Many distributed systems for stream-oriented communication are built on top of Internet protocol stack. Internet provides differentiating classes for data using differentiated services. Sending host can mark outgoing packets as belonging to one of several classes. Expedited forwarding class specifies that the packet should be forwarded by the router with absolute priority. With assured forwarding class, traffic is divided into 4 subclasses along with three ways to drop packets if the network gets congested. This means a range of priorities can be assigned to the packets to differentiate time-critical packets from non-critical ones. Stream Synchronization ⚫ Maintains temporal relationships between streams/substreams , for example between discrete data stream and continuous data stream, or between continuous data streams ⚫ Synchronization takes place at the level of data units ⚫ Synchronization mechanisms concerned with synchronizing data streams and distribution of the mechanism in a networked environment ⚫ Multimedia middleware offers a collection of interfaces for controlling audio and video streams including interfaces for controlling devices such as monitors, cameras, microphones etc. ⚫ Each device and stream has its own high level interface including interfaces for notifying an application when some event occurred. Latter used for writing handlers for synchronizing streams. ⚫ Distribution of synchronization mechanism - receiving side has to have complete synchronization specification locally available ⚫ This approach is followed by MPEG streams ⚫ MPEG standards form a collection of algorithms for compressing video and audio ⚫ MPEG -2 designed for compressing broadcast quality video into 4 to 6 Mbps. Unlimited number of continuous and discrete streams merged into single stream. Input stream turned into a stream of packets that carry timestamp based on 90kHz clock. These streams multiplexed into a program stream consisting of variable length packets with common time base. Receiving side demultiplexes the stream using timestamp for interstream synchronization. Better to do synchronization at the sender rather than at receiver. Stream Control Transmission Protocol (SCTP) • SCTP is a reliable transport protocol operating on top of a connectionless packet network such as IP. It is described in RFC 4960, RFC 3286. It offers the following services to its users: -- acknowledged error-free non-duplicated transfer of user data -- data fragmentation to conform to discovered path size -- sequenced delivery of user messages within multiple streams, with an option for order-of-arrival delivery of individual user messages -- optional bundling of multiple user messages into a single SCTP packet -- network-level fault tolerance through supporting of multi-homing at either or both ends of an association • The design of SCTP includes appropriate congestion avoidance behavior and resistance to flooding and masquerade attacks. ⚫ The Stream Control Transmission Protocol (SCTP) is a new IP transport protocol, existing at an equivalent level with UDP (User DatagramProtocol) and TCP (Transmission Control Protocol), which provide transport layer functions to many Internet applications. ⚫ SCTP has been approved by the IETF as a Proposed Standard ⚫ Like TCP, SCTP provides a reliable transport service, ensuring that data is transported across the network without error and in sequence. ⚫ Like TCP, SCTP is a session-oriented mechanism, meaning that a relationship is created between the endpoints of an SCTP association prior to data being transmitted, and this relationship is maintained until all data transmission has been successfully completed. ⚫ Unlike TCP, SCTP provides a number of functions that are critical for telephony signaling transport, and at the same time can potentially benefit other applications needing transport with additional performance and reliability. The original framework for the SCTP definition is described in [3]. Network Transport SCTP User Application SCTP Transport Service IP Network Service SCTP User Application SCTP Transport Service IP Network Service One or more IP Address Appearances One or more IP Address Appearances SCTP Node A SCTP Node B An SCTP Association Message Format Common Header Chunk No: 1 … Chunk No: n Chunk ID : 0 through 255. Each ID has Chunk Type defined as follows: ⚫ 0 - Payload Data (DATA) ⚫ 1 - Initiation (INIT) ⚫ 2 - Initiation Acknowledgement (INIT ACK) ⚫ 3 - Selective Acknowledgement (SACK) ⚫ 4 - Heartbeat Request (HEARTBEAT) ⚫ 5 - Heartbeat Acknowledgement (HEARTBEAT ACK) ⚫ 6 - Abort (ABORT) ⚫ 7 - Shutdown (SHUTDOWN) ⚫ 8 - Shutdown Acknowledgement (SHUTDOWN ACK) ⚫ 9 - Operation Error (ERROR) ⚫ Etc … SCTP Common Header Format Source Port No: Destination Port No : Verification Tag Check Sum ⚫ Source Port Number: 16 bits (unsigned integer). This is the SCTP sender’s port number. It can be used by the receiver in combination with the source IP address, the SCTP destination port, and possibly the destination IP address to identify the association to which this packet belongs. The port number 0 MUST NOT be used. ⚫ Destination Port Number: 16 bits (unsigned integer). This is the SCTP port number to which this packet is destined. The receiving host will use this port number to de-multiplex the SCTP packet to the correct receiving endpoint/application. The port number 0 MUST NOT be used. • Verification Tag: 32 bits (unsigned integer). The receiver of this packet uses the Verification Tag to validate the sender of this SCTP packet. On transmit, the value of this Verification Tag must be set to the value of the Initiate Tag received from the peer endpoint during the association initialization, with the following exceptions: - A packet containing an INIT chunk MUST have a zero Verification Tag. - A packet containing a SHUTDOWN COMPLETE chunk with the T bit set MUST have the Verification Tag copied from the packet with the SHUTDOWN ACK chunk. - A packet containing an ABORT chunk may have the verification tag copied from the packet that caused the ABORT to be sent. An INIT chunk MUST be the only chunk in the SCTP packet carrying it. • Checksum: 32 bits (unsigned integer). This field contains the

Basic SCTP Features • SCTP is a unicast protocol, and supports data exchange between exactly 2 endpoints, although these may be represented by multiple IP addresses. • SCTP provides reliable transmission, detecting when data is discarded, reordered, duplicated or corrupted, and retransmitting damaged data as necessary. SCTP transmission is full duplex. • SCTP is message oriented and supports framing of individual message boundaries. In comparison, TCP is byte oriented and does not preserve any implicit structure within a transmitted byte stream without enhancement. • SCTP is rate adaptive similar to TCP, and will scale back data transfer to the prevailing load conditions in the network. It is designed to behave cooperatively with TCP sessions attempting to use the same bandwidth SCTP Multi-Streaming Feature • The name Stream Control Transmission Protocol is derived from the multi-streaming function provided by SCTP. This feature allows data to be partitioned into multiple streams that have the property of independently sequenced delivery, so that message loss in any one stream will only initially affect delivery within that stream, and not delivery in other streams. SCTP accomplishes multi-streaming by creating independence between data transmission and data delivery. In particular, each payload DATA "chunk" in the protocol uses two sets of sequence numbers, a Transmission Sequence Number that governs the transmission of messages and the detection of message loss, and the Stream ID/Stream Sequence Number pair, which is used to determine the sequence of delivery of received data. This independence of mechanisms allows the receiver to determine immediately when a gap in the transmission sequence occurs (e.g., due to message loss), and also whether or not messages received following the gap are within an affected stream. SCTP Multi-Homing Feature ⚫ Another core feature of SCTP is multi-homing, or the ability for a single SCTP endpoint to support multiple IP addresses. The benefit of multi-homing is potentially greater survivability of the session in the presence of network failures. To support multi-homing, SCTP endpoints exchange lists of addresses during initiation of the association. Each endpoint must be able to receive messages from any of the addresses associated with the remote endpoint; in practice, certain operating systems may utilize available source addresses in round robin fashion, in which case receipt of messages from different source addresses will be the normal case. A single port number is usedacrosstheentireaddresslistatanendpointforaspecificsession Security Objectives ⚫ As a common transport protocol designed to reliably carry time-sensitive user messages, such as billing or signaling messages for telephony services, between two networked endpoints, SCTP has the following security objectives. availability of reliable and timely data transport services integrity of the user-to-user information carried by SCTP SCTP Responses to Potential Threats • SCTP may potentially be used in a wide variety of risk situations. It is important for operators of systems running SCTP to analyze their particular situations and decide on the appropriate countermeasures. • Operators of systems running SCTP should consult [RFC2196] for guidance in securing their site. Countering Insider Attacks • The principles of [RFC2196] should be applied to minimize the risk of theft of information or sabotage by insiders. Such procedures include publication of security policies, control of access at the physical, software, and network levels, and separation of service ⚫ Protecting against Data Corruption in the Network ⚫ Protecting Confidentiality ⚫ As with the supplementary checksum service, user data encryption MAY be performed by the SCTP user application. ⚫ Alternately, the user application may use an implementation-specific API to request that the IP Encapsulating Security Payload (ESP) [RFC4303] be used to provide confidentiality and integrity. ⚫ Protecting against Blind Denial-of-Service Attacks A blind attack is one where the attacker is unable to intercept or otherwise see the content of data flows passing to and from the target SCTP node. Blind denial-of-service attacks may take the form of flooding, masquerade, or improper monopolization of services • Flooding – The objective of flooding is to cause loss of service and incorrect behavior at target systems through resource exhaustion, interference with legitimate transactions, and exploitation of buffer-related software bugs. Flooding may be directed either at the SCTP node or at resources in the intervening IP Access Links or the Internet. Where the latter entities are the target, flooding will manifest itself as loss of network services, including potentially the breach of any firewalls in place – In general, protection against flooding begins at the equipment design level, where it includes measures such as: - avoiding commitment of limited resources before determining that the request for service is legitimate. - giving priority to completion of processing in progress over the acceptance of new work. - identification and removal of duplicate or stale queued requests for service. - not responding to unexpected packets sent to non-unicast addresses

• Network equipment should be capable of generating an alarm and log if a suspicious increase in traffic occurs. • Blind Masquerade Masquerade can be used to deny service in several ways: - by tying up resources at the target SCTP node to which the impersonated node has limited access. For example, the target node may by policy permit a maximum of one SCTP association with the impersonated SCTP node. The masquerading attacker may attempt to establish an association purporting to come from the impersonated node so that the latter cannot do so when it requires it. - by deliberately allowing the impersonation to be detected, thereby provoking counter-measures that cause the impersonated node to be locked out of the target SCTP node. - by interfering with an established association by inserting extraneous content such as a SHUTDOWN request. ⚫ SCTP reduces the risk of blind masquerade attacks through IP spoofing by use of the four-way startup handshake. Because the initial exchange is memory-less, no lockout mechanism is triggered by blind masquerade attacks. In addition, the INIT ACK containing the State Cookie is transmitted back to the IP address from which it received the INIT. Thus, the attacker would not receive the INIT ACK containing the State Cookie. SCTP protects against insertion of extraneous packets into the flow of an established association by use of the Verification Tag. Logging of received INIT requests and abnormalities such as unexpected INIT ACKs might be considered as a way to detect patterns of hostile activity. ⚫ Improper Monopolization of Services ✔ Attacks under this heading are performed openly and legitimately by the attacker. They are directed against fellow users of the target SCTP node or of the shared resources between the attacker and the target node. Possible attacks include the opening of a large number of associations between the attacker’s node and the target, or transfer of large volumes of information within a legitimately established association. ✔ Policy limits should be placed on the number of associations per adjoining SCTP node. SCTP user applications should be capable of detecting large volumes of illegitimate or "no-op" messages within a given association and either logging or terminating the association as a result, based on local policy. ⚫ SCTP Interactions with Firewalls ▪ It is helpful for some firewalls if they can inspect just the first fragment of a fragmented SCTP packet and unambiguously determine whether it corresponds to an INIT chunk (for further information, refer to [RFC1858]). ▪ Accordingly, the requirements, (1) an INIT chunk MUST NOT be bundled with any other chunk in a packet, and (2) a packet containing an INIT chunk MUST have a zero Verification Tag. 3GPP ⚫ The 3rd Generation Partnership Project (3GPP) is a collaboration between groups of telecommunications associations, to make a globally applicable third-generation (3G) is a collaboration between groups of telecommunications associations, to make a globally applicable third-generation (3G) mobile phone) is a collaboration between groups of telecommunications associations, to make a globally applicable third-generation (3G) mobile phone system specification within the scope of the International Mobile Telecommunications-2000) is a collaboration between groups of telecommunications associations, to make a globally applicable third-generation (3G) mobile phone system specification within the scope of the International Mobile Telecommunications-2000 project of the International Telecommunication Union) is a collaboration between groups of telecommunications associations, to make a globallyapplicablethird-generation(3G)mobilephonesystem ⚫ Much of the standard addresses upgrading 3G UMTS to 4G mobile communications technology, which is essentially a mobile broadband system with enhanced multimedia services built on top. ⚫ The standard includes: ⚫ Peak download rates of 326.4 Mbit/s for 4x4 antennas, and 172.8 Mbit/s for 2x2 antennas (utilizing 20 MHz of spectrum). ⚫ Peak upload rates of 86.4 Mbit/s for every 20 MHz of spectrum using a single antenna. ⚫ Five different terminal classes have been defined from a voice centric class up to a high end terminal that supports the peak data rates. All terminals will be able to process 20 MHz bandwidth. ⚫ At least 200 active users in every 5 MHz cell. (Specifically, 200 active data clients) Security Issues ⚫ Security documents can be located at ftp://ftp.3gpp.org ⚫ GSM was the first public telephone system to use integrated cryptographic mechanisms GSM security features • Secure user access to telecommunications services Identity of user authenticated by network operator • User and signaling traffic confidentiality Protects user voice and data traffic, and signaling data from eavesdropping on radio path • User anonymity Attacker who knows user’s IMSI can be prevented from tracking location of user and eavesdropping on radio path GSM security mechanisms • Cryptographic authentication verifies the subscription with the home network when service is requested – Challenge / response authentication protocol based on a subscriber specific secret authentication key • Radio interface encryption prevents eavesdropping and authenticates the use of the radio channel – The encryption mechanism is based on a symmetric stream cipher – The key for encryption is established as part of the authentication protocol • The allocation and use of temporary identities helps to provide user anonymity Multicast Communication ⚫ Sending data to multiple receivers ⚫ Explicit communication paths set up could be at Application Level for peer-to-peer solutions ⚫ Without explicit communication paths, gossip based information dissemination provides simple but less efficient way to implement multicasting. Application level multicasting ⚫ Nodes organize into an overlay network that is used to disseminate information to its members ⚫ Network routers not involved in group membership ⚫ Overlay network could be organized into a tree or a mesh network. Former provides a unique overlay path between every pair of nodes, while latter has each node connected to multiple neighbors – higher robustness in the event a connection breaks Multicast Session ⚫ Node generates a multicast identifier mid (randomly chosen 160 bit key). It then looks up succ(mid) that is the node responsible for this key and promotes it to become the root of the multicast tree that is used to send data to interested nodes ⚫ To join the tree, a node P executes operation LOOKUP(mid) that allows a lookup message with request to join the multicast group mid to be routed from P to succ(mid). ⚫ On the way up to the root, join request will add forwarder nodes or helpers for the group ⚫ Multicasting implemented by a node sending a multicast message towards the root by executing LOOKUP(mid) after which message can be sent along the tree. Gossip based data dissemination ⚫ Spreading information without explicit communication paths in large distributed systems using epidemic protocols. ⚫ These protocols rapidly propagate information among large collection of nodes using only local information without any central component to coordinate information dissemination ⚫ Avoid write conflicts by allowing only a single node to initiate updates for a specific data item ⚫ Node is infected if it holds data that it is willing to spread to other nodes. ⚫ Node that has not seen the data is called susceptible. ⚫ Updated node that is not willing or able to spread the data is said to be removed. ⚫ Data is timestamped ⚫ Anti-entropy model of propagation has three approaches for updates for node P propagating to random node Q: ⚫ P only pushes its own updates to Q ⚫ P only pulls its own updates from Q ⚫ P and Q send updates to each other (push-pull approach) – This is the best ⚫ Rumor spreading or gossiping allows node P to push update to arbitrary node Q if it is not yet updated. If Q already updated by another node, P loses interest in spreading the update further- it becomes removed. ⚫ Deletion of data item needs the use of death certificates to be recorded and spread through all the nodes. ⚫ Death certificates are time-stamped and they are removed after a maximum propagation time has elapsed Conclusion In this presentation, following topics were discussed: ⚫ Three popular models of communication in distributed systems: ⚫ Remote Procedure Calls (RPC) ⚫ Message-oriented Middleware (MOM) ⚫ Data Streaming, discussion of SCTP, 3GPP ⚫ Sending data to multiple receivers or Multicasting References: [1] Stewart, R., Xie, Q., Morneault, K., Sharp, C., Schwarzbauer, H., Taylor, T., Rytina, I., Kalla, M., Zhang, L. and V. Paxson, "Stream Control Transmission Protocol", RFC 2960, October 2000. [2] Stewart, Sharp, et. al., "SCTP Checksum Change", Work in Progress. [3] Ong, L., Rytina, I., Garcia, M., Schwarzbauer, H., Coene, L., Lin, H., Juhasz, I., Holdrege, M. and C. Sharp, "Framework Architecture for Signaling Transport", RFC 2719, October 1999. [4] Jungmeier, Rescorla and Tuexen, "TLS Over SCTP", Work in Progress. [5] www.ietf.org [6] [6] RFC4960 [7] [7] RFC3286 [8] RFC2196 [9] RFC1858 [10] RFC3314 [11] ftp://ftp.3gpp.org Bibliography 1. A. Tanenbaum, M.V. Steen, Distributed Systems: Principles and Paradigms, Pearson(2nd Ed), 2007. 3. Synchronization in Distributed Systems ■ In a centralized system: all processes reside on the same system utilize the same clock. ■ In a distributed system: like synchronize everyone’s watch in the classroom. Global Time ■ Global Time is utilized to provide timestamps for processes and data. ■ ✔ Physical clock: concerned with “People” time ■ ✔ Logical clock: concerned with relative time and maintain logical consistency Physical Clocks ■ There are two aspects: ✔ Obtaining an accurate value for physical time ✔ Synchronizing the concept of physical time throughout the distributed system ✔ These can be implemented using centralized algorithms or distributed algorithms Obtaining an Accurate Physical Time ■ A physical time server is needed to access the current time from a universal time coordinator (UTC). ■ Two sources for UTC: ✔ WWV shortwave radio station in Ft. Collins, Colorado ✔ Geostationary Operational Environmental Satellites (GEOS) Synchronizing Physical Time ■ The difference in time between two clocks due to drifting is defined as clock skew. As long as any and every two clocks differ by a value less than the maximum skew value, the time service is considered to be maintaining synchronization. How to synchronize two clocks in A and B? ■ The information necessary to read the value must be communicated across the network to location B. ■ B’s clock value must be read. ■ B’s clock value is communicated back to location A. ■ B’s clock value is adjusted to reflect the time necessary to travel across the network. ■ B’s clock value is compared to A’s clock value. Centralized Physical Time Services ■ Broadcast Based ■ Request Driven Broadcast Based – first approach ■ The centralized time server’s action: The physical time service broadcasts periodically the current time to members of the distributed systems. ■ The participants’ action: ✔ If a given participant’s clock is ahead of the time server’s clock, the participant slows down its clock so that it will continually move closer to the accurate time. ✔ If a participant’s clock is behind the time server’s clock, the participant moves its clock forward. Alternatives do include gradually speeding up the clock.

For example Current time = 720 Location A Broadcast based Time server Current time=740 Delay of 10 Current time=720 Adjusted current time=750 New current time=750 Location A Broadcast Based – second approach (Berkeley algorithm) Current time=720 Move forward=6 Location A Current time=740 Adjusted location A =730 Adjusted location B =738 Average and the new current time=736 Time Server Current time=732 Slow clock down to accommodate 2 Location B 1 1 2 2 4 5 1. Current time = 740 2. My current time = 720 3. My current time = 732 4. Adjust forward = 6 5. Adjust slowdown to accommodate 2 Delay=10 Delay=6 Request Driven Current time=730 Adjusted time=750 New current time=750 Current time=740 Location A Timer Server Request for current time Current time=740 Delay=10 Distributed Physical Time Service ■ Each location broadcasts its current time at predefined set intervals. Once a location has broadcast its time, it starts a timer. It then collects time messages that it receives. Each time message that arrives is stamped with the local current time. This process continues until the timer expires. Upon the expiration of the timer, each message is adjusted to reflect the network delay time estimated for the message source. At this stage, the participant calculates the average time according to one of the following approaches: ■ Calculate the average of all messages 720 724 726 718 722 723 Adjusted received times ■ Delete the times that are above the threshold and then average the rest. 760 X 724 726 718 702 X 723 Adjusted received times The numbers besides X are deleted. The rest are averaged. ■ Discard the highest x and the lowest x values and then average 760 X 724 726 718 702 X 723 703 X 765 X Adjusted received times Logical Clocks ■ Why Logical Clocks? It is difficult to utilize physical clocks to order events uniquely in distributed systems. ■ The essence of logical clocks is based on the happened-before relationship presented by Lamport. Happen-Before Relationship ■ If two events, a and b, occurred at the same process, they occurred in the order of which they were observed. That is, a -> b. ■ If a sends a message to b, then a -> b. That is, you cannot receive something before it is sent. This relationship holds regardless of where events a and b occur. ■ The happen-before relationship is transitive. If a happens before b and b happens before c, then a happens before c. That is, if a -> b and b -> c, then a -> c. Logical Ordering ■ If T(a) is the timestamp for event a, the following relationships must hold in a distributed system utilizing logical ordering. ■ If two events, a and b, occurred at the same process, they occurred in the order of which they were observed. That is T(a) -> T(b). ■ If a sends a message to b, then T(a) -> T(b). ■ If a happens before b and b happens before c, T(a) -> T(b), T(b)-> T(c), and T(a) -> T(c). For example Process 1 Process 2 Process 3 A B C 1 D 2 E 1 F 2 A>B>C>D>F E Lamport’s Algorithm ■ Each process increments its clock counter between every two consecutive events. ■ If a sends a message to b, then the message must include T(a). Upon receiving a and T(a), the receiving process must set its clock to the greater of [T(a)+d, Current Clock]. That is, if the recipient’s clock is behind, it must be advanced to preserve the happen-before relationship. Usually d=1. For example Process 1 Process 2 Process 3 A(1) B(2) C(3) D(4) E(1) F(5) Total Ordering with Logical Clocks Process 1 Process 2 Process 3 A(1.1) B(2.1) D(4.2) E(1.3) F(5.3) C(3.2) A>E>B>C>D>F Mutual Exclusion ■ In single-processor systems, critical regions are protected using semaphores, monitors, and similar constructs. ■ In distributed systems, since there is no shared memory, these methods cannot be used. A Centralized Algorithm ■ Advantages: It is fair, easy to implement, and requires only three messages per use of a critical region (request, grant, release). ■ Disadvantages: single point of failure. coordinator process Request Grant Enter crical section Exit Release Distributed Algorithm REQ REQ REQ REQ OK OK Token Ring Algorithm A Comparison of the Three Algorithms Algorithm Messages per entry/exit Delay before entry Problems Centralized 3 2 Coordinator crash Distributed 2(n-1) 2(n-1) Crash of any process Token ring 1 to ∞ 0 to n-1 Lost token, process crash Election Algorithm ■ The bully algorithm ■ When a process notices that the coordinator is no longer responding to requests, it initiates an election. A process, P, holds an election as follows: ✔ P sends an ELECTION message to all processes with higher numbers. ✔ If no one responds, P wins the election and becomes coordinator. ✔ If one of the higher-ups answers, it takes over. P’s job is done. For example 7 1 2 5 4 3 6 Election 7 1 2 5 4 3 6 Ok 7 1 2 5 4 3 6 Election 7 1 2 5 4 3 6 Ok 7 1 2 5 4 3 6 Coordinator ■ A Ring Algorithm 1 2 4 5 3 7 6 2 2 3 2 3 4 2 3 4 5 2 3 4 5 6 2 3 4 5 6 1 6 Atomic Transactions ■ All the synchronization techniques we have studied so far are essentially low level, like semaphores. ■ What we would really like is a much higher-level abstraction such as atomic transaction. For example ■ Atomic bank transactions: 1. Withdraw(amount, account1) 2. Deposit(amount, account2) Stable Storage ■ Stable storage is designed to survive anything except major calamities such as floods and earthquakes. ■ Stable storage can be implemented with a pair of ordinary disks. ■ Stable storage is well suited to applications that require a high degree of fault tolerance, such as atomic transactions. s a o h t f b w s a t f b w s a’ o h t f b w s a t f b w s a o h t f b w s a t f b w Stable storage Stable storage Stable storage Drive 1 Drive 2 (a) Stable storage (b) Crash after drive 1 is updated © Bad spot Transaction Primitives ■ 1 BEGIN_TRANSACTION: Mark the start of a transaction. ■ 2 END_TRANSACTION: Terminate the transaction and try to commit. ■ 3 ABORT_TRANSACTION: Kill the transaction; restore the old values. ■ 4 READ: Read data from a file (or other object). ■ 5 WRITE: Write data to a file (or other object). ■ For example, ■ BEGIN_TRANSACTION ■ reserve Austin-Houston; ■ reserve Houston-Los Angeles; ■ reserve Los Angeles-Seatle; ■ END_TRANSCATION Properties of Transactions ■ 1 Atomic: To the outside world, the transaction happens indivisibly. ■ 2 Consistent: The transaction does not violate system invariants. ■ 3 Isolated: Concurrent transactions do not interfere with each other. 4 Durable: Once a transaction commits, the changes are permanent. Isolated or serializable ■ Isolated or serializable means that if two or more transactions are running at the same time, to each of them and to other processes, the final result looks as though all transactions ran sequentially in some (system dependent) order. An example ■ BEGIN_TRANACATION ■ X = 0; ■ X=X+1; ■ END_TRANSACTION ■ (a) ■ BEGIN_TRANSACTION ■ X=0; ■ X= X+2; ■ END_TRANSACTION ■ (b) ■ BEGIN_TRANSACTION ■ X=0; ■ X=X+3; ■ END_TRANSACTION ■ (c ) Schedule 1 x=0; x=x+1; x=0; x=x+2; x=0; x=x+3; legal Schedule 2 x=0; x=0; x=x+1; x=x+2; x=0; x=x+3; legal Schedule 3 x=0; x=0; x=x+1; x=0; x=x+2; x=x+3; illegal Nest Transactions ■ Transactions may contain subtransactions, often called nested transactions. ■ If the subtransaction commits and the parent transaction aborts, the permanence applies only to top-level transactions. Implementation ■ Private Workspace 1 2 0 0 1 2 1 2 0 1 2 Index 0’ 3’ 0 3 Index Index 0 1 2 0’ 1 2 3’ 0 1 2 3 Private workspace ■ Writeahead log x=0; y=0; BEGIN_TRANSACTION x=x+1; log: x=0/1; y=y+2; log: x=0/1; y=0/2; x=y * y; log: x=0/1; y=0/2; x=1/4; END_TRANSACTION Achieving atomic commit in a distributed system ■ Two-Phase Commit Protocol Coordinator Subordinates Write “Prepare” in the log Send “Prepare” message Write “Ready” in the log Send “Ready” message Collect all replies Phase 1 Phase 2 Write log record (if all are ready, commit; if not, abort) Send “Commit” message Write “Commit” in the log Commit Send “Finished” message Concurrency Control ■ When multiple transactions are executing simultaneously in different processes, some mechanism is needed to keep them out of each other’s way. That mechanism is called a concurrency control algorithm. Concurrency control algorithms ■ Locking ✔ In the simplest form, when a process needs to read or write a file (or other object) as part of a transaction, it first locks the file. ✔ Distinguishing read locks from write locks. ✔ The unit of locking can be an individual record or page, a file, or a larger item. ■ Two-phase locking ✔ The process first acquires all the locks it needs during the growing phase, then releases them during the shrinking phase. ✔ In many systems, the shrinking phase does not take place until the transaction has finished running and has either committed or aborted. This policy is called strict two-phase locking. Two-phase locking Time Growing phase Shrinking phase Lock point Number of locks ■ Optimistic Concurrency Control A second approach to handling multiple transactions at the same time is optimistic concurrency control. The idea is simple: just go ahead and do whatever you want to, without paying attention to what anybody else is doing. If there is a problem, worry about it later. ■ Timestamps TRD TWR T (α) (α) (β) TWR TRD T (α) (α) (β) Write TRD T (β) (γ) TWR T (β) (γ) Do tentative write Abort Do tenative Abort write TWR T (β) (γ) TTENT T (γ) (β) Abort Read T (α) (β) TTENT (α) (γ) TWR T (β) TWR Ok Wait Abort